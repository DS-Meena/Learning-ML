{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a44d581",
   "metadata": {},
   "source": [
    "# Diffusion Models\n",
    "\n",
    "- Diffusion models work by gradually adding noise to data and then learning to reverse this process.\n",
    "- They consist of two main processes:\n",
    "    - Forward diffusion (adding noise gradually)\n",
    "    - Reverse diffusion (removing noise gradually)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c81fd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 06:34:58.597848: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-28 06:34:58.612887: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-28 06:34:58.751563: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-28 06:34:58.866344: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745822098.956955     809 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745822098.984969     809 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745822099.235627     809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745822099.235682     809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745822099.235683     809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745822099.235684     809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-28 06:34:59.262640: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc19607",
   "metadata": {},
   "source": [
    "### 1. Noise Schedule\n",
    "\n",
    "```python\n",
    "self.beta = tf.linspace(beta_start, beta_end, time_steps)\n",
    "self.alpha = 1 - self.beta\n",
    "self.alpha_bar = tf.math.cumprod(self.alpha)\n",
    "```\n",
    "\n",
    "- Controls how noise is added during forward diffusion\n",
    "- Beta increases linearly from beta_start to beta_end\n",
    "- Alpha and Alpha_bar are used to calcualte noise levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c913e8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta is [ 2.  4.  6.  8. 10. 12. 14. 16. 18. 20.] \n",
      " alpha is [ -1.  -3.  -5.  -7.  -9. -11. -13. -15. -17. -19.] \n",
      " alpha bar is [2.0000000e+00 8.0000000e+00 4.8000000e+01 3.8400000e+02 3.8400000e+03\n",
      " 4.6080000e+04 6.4512000e+05 1.0321920e+07 1.8579456e+08 3.7158912e+09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 06:36:17.871512: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "beta_start = 2\n",
    "beta_end = 20\n",
    "time_steps = 10\n",
    "\n",
    "beta = tf.linspace(beta_start, beta_end, time_steps)\n",
    "alpha = 1 - beta\n",
    "\n",
    "# This is cumulative product (2 * 4 * 8 * 10)\n",
    "alpha_bar = tf.math.cumprod(beta)\n",
    "\n",
    "print(f\"Beta is {beta} \\n alpha is {alpha} \\n alpha bar is {alpha_bar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcd377c",
   "metadata": {},
   "source": [
    "### 2. Forward Diffusion\n",
    "\n",
    "- Gradually adds noise to the input data\n",
    "- The amount of noise depends on the timestep t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d35ca1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha t is 384.0\n"
     ]
    }
   ],
   "source": [
    "t = 3\n",
    "\n",
    "# Add noise according to the noise schedule\n",
    "alpha_t = tf.gather(alpha_bar, t)\n",
    "print(f\"alpha t is {alpha_t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "270610c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha t becomes [[[[384.]]]]\n"
     ]
    }
   ],
   "source": [
    "alpha_t = tf.reshape(alpha_t, (-1, 1, 1, 1))\n",
    "print(f\"alpha t becomes {alpha_t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0cfa556",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m noise \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(shape\u001b[38;5;241m=\u001b[39m\u001b[43mx_0\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(noise)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# return tf.sqrt(alpha_t) * x_0 + tf.sqrt(1 - alpha_t) * noise, noise\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_0' is not defined"
     ]
    }
   ],
   "source": [
    "noise = tf.random.normal(shape=x_0.shape)\n",
    "print(noise)\n",
    "# return tf.sqrt(alpha_t) * x_0 + tf.sqrt(1 - alpha_t) * noise, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd81f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DiffusionModel(tf.keras.Model):\n",
    "    def __init__(self, time_steps=1000, beta_start=1e-4, beta_end=0.02):\n",
    "        super().__init__()\n",
    "\n",
    "        #Define noise schedule\n",
    "        self.time_steps = time_steps\n",
    "        self.beta = tf.linspace(beta_start, beta_end, time_steps)\n",
    "        self.alpha = 1 - self.beta\n",
    "        self.alpha_bar = tf.math.cumprod(self.alpha)\n",
    "\n",
    "        # Define the U-Net architecture for noise prediction\n",
    "        self.model = self.build_unet()\n",
    "\n",
    "    def build_unet(self):\n",
    "        # Simple U-Net architecture\n",
    "        inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "        x = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
    "        x = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "        x = tf.keras.layers.Conv2D(1, 3, padding='same')(x)\n",
    "        return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "    \n",
    "    def forward_diffusion(self, x_0, t):\n",
    "        # Add noise according to the noise schedule\n",
    "        alpha_t = tf.gather(self.alpha_bar, t)\n",
    "        alpha_t = tf.reshape(alpha_t, (-1, 1, 1, 1))\n",
    "        \n",
    "        noise = tf.random.normal(shape=x_0.shape)\n",
    "        return tf.sqrt(alpha_t) * x_0 + tf.sqrt(1 - alpha_t) * noise, noise\n",
    "    \n",
    "    def train_step(self, x_0):\n",
    "        # Sample random timesteps\n",
    "        t = tf.random.uniform(\n",
    "            shape=(tf.shape(x_0)[0],),\n",
    "            minval=0,\n",
    "            maxval=self.time_steps,\n",
    "            dtype=tf.int32\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward diffusion\n",
    "            x_noisy, noise = self.forward_diffusion(x_0, t)\n",
    "            \n",
    "            # Predict noise\n",
    "            predicted_noise = self.model(x_noisy, training=True)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = tf.reduce_mean(tf.square(noise - predicted_noise))\n",
    "        \n",
    "        # Update model parameters\n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        \n",
    "        return {'loss': loss}\n",
    "\n",
    "    def sample(self, n_samples):\n",
    "        # Start from random noise\n",
    "        x = tf.random.normal(shape=(n_samples, 28, 28, 1))\n",
    "        \n",
    "        # Gradually denoise\n",
    "        for t in range(self.time_steps - 1, -1, -1):\n",
    "            t_tensor = tf.constant([t], dtype=tf.int32)\n",
    "            t_tensor = tf.repeat(t_tensor, n_samples)\n",
    "            \n",
    "            # Predict noise\n",
    "            predicted_noise = self.model(x)\n",
    "            \n",
    "            alpha_t = tf.gather(self.alpha, t)\n",
    "            alpha_bar_t = tf.gather(self.alpha_bar, t)\n",
    "            \n",
    "            # Update sample\n",
    "            if t > 0:\n",
    "                noise = tf.random.normal(shape=x.shape)\n",
    "            else:\n",
    "                noise = 0\n",
    "                \n",
    "            x = (1 / tf.sqrt(alpha_t)) * (\n",
    "                x - (1 - alpha_t) / tf.sqrt(1 - alpha_bar_t) * predicted_noise\n",
    "            ) + tf.sqrt(self.beta[t]) * noise\n",
    "            \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "a1400de1",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Training data sample\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed14117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapes_dataset import create_shape_dataset\n",
    "\n",
    "dataset = create_shape_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc6ed4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can train the diffusion model\n",
    "diffusion = DiffusionModel()\n",
    "diffusion.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7088a560",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert a partially known TensorShape (None, 28, 28, 1) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/training/Learning-ML/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[23], line 41\u001b[0m, in \u001b[0;36mDiffusionModel.train_step\u001b[0;34m(self, x_0)\u001b[0m\n\u001b[1;32m     32\u001b[0m t \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[1;32m     33\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(tf\u001b[38;5;241m.\u001b[39mshape(x_0)[\u001b[38;5;241m0\u001b[39m],),\n\u001b[1;32m     34\u001b[0m     minval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     35\u001b[0m     maxval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_steps,\n\u001b[1;32m     36\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# Forward diffusion\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     x_noisy, noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_diffusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# Predict noise\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     predicted_noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x_noisy, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[23], line 27\u001b[0m, in \u001b[0;36mDiffusionModel.forward_diffusion\u001b[0;34m(self, x_0, t)\u001b[0m\n\u001b[1;32m     24\u001b[0m alpha_t \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_bar, t)\n\u001b[1;32m     25\u001b[0m alpha_t \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(alpha_t, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 27\u001b[0m noise \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39msqrt(alpha_t) \u001b[38;5;241m*\u001b[39m x_0 \u001b[38;5;241m+\u001b[39m tf\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alpha_t) \u001b[38;5;241m*\u001b[39m noise, noise\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert a partially known TensorShape (None, 28, 28, 1) to a Tensor."
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = diffusion.fit(dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537f34b6",
   "metadata": {},
   "source": [
    "## Generate Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf4e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and visualize samples\n",
    "generated_samples = diffusion.sample(n_samples=5)\n",
    "\n",
    "# Visualize generated samples\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(generated_samples[i].numpy().squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss During Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fb471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "diffusion = DiffusionModel()\n",
    "\n",
    "# Compile the model\n",
    "diffusion.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
    "\n",
    "# Train the model (assuming you have a dataset)\n",
    "diffusion.fit(dataset, epochs=100)\n",
    "\n",
    "# Generate new samples\n",
    "samples = diffusion.sample(n_samples=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1d0867",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
