{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df4789fb",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Open-source development framework for LLM applications.\n",
    "Python and JavaScript (TypeScript) packages\n",
    "\n",
    "Focused on composition and modularity.\n",
    "\n",
    "Key value adds:\n",
    "1. Modular components\n",
    "2. Use cases: Common ways to combine components\n",
    "\n",
    "### Models\n",
    "- LLMs: 20+ integrations\n",
    "- Chat Models\n",
    "- Text Embedding Models: 10+ integrations\n",
    "\n",
    "### Prompts\n",
    "- Prompt Templates\n",
    "- Output Parsers: 5+ implementations\n",
    "    - Retry/fixing logic\n",
    "- Example Selectors: 5+ implementations\n",
    "\n",
    "### Indexes\n",
    "- Document Loaders: 50+ implementations\n",
    "- Text Splitters: 10+ implementations\n",
    "- Vector stores: 10+ integrations\n",
    "- Retrievers: 5+ integrations/implementations\n",
    "\n",
    "### Chains\n",
    "- Prompt + LLM + Output parsing\n",
    "- Can be used as building blocks for longer chains\n",
    "- More application specific chains: 20+ types\n",
    "\n",
    "### Agents\n",
    "- Agent Types: 5+ types\n",
    "    - Algorithms for getting LLMs to use tools\n",
    "- Agent Toolkits: 10+ implementations\n",
    "    - Agents armed with specific tools for a specific application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee8eeef",
   "metadata": {},
   "source": [
    "# Models, Prompts and Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b1ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-proj---o727a8k7j_AaGy1t0WfOdSg4A'\n",
    "\n",
    "from openai import OpenAI \n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ['OPENAI_API_KEY'],   # Default can be omitted\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6583111",
   "metadata": {},
   "source": [
    "## Chat API: Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f29cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\n",
    "        \"role\": \"user\", \n",
    "        \"content\": prompt\n",
    "    }]\n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "035cdf20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 equals 2.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\"What is 1+1?\")\n",
    "\n",
    "# '1+1 equals 2.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e2bfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\"I am really frustrated that my blender lid flew off and splattered my kitchen walls with smoothie! And to make matters worse, the warranty doesn\\'t cover the cost of cleaning up my kitchen. I could really use your help right now, friend.\"\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\"\n",
    "\n",
    "style = \"\"\"American English in a calm and respectful tone\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Translate the text that is delimited by triple backticks into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "# response = get_completion(prompt)\n",
    "# response\n",
    "\n",
    "\"\"\"\n",
    "\"I am really frustrated that my blender lid flew off and splattered my kitchen walls with smoothie! And to make matters worse, the warranty doesn't cover the cost of cleaning up my kitchen. I could really use your help right now, friend.\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cd93cb",
   "metadata": {},
   "source": [
    "## Chat API : LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1489a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade langchain\n",
    "# !pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ed1cdd",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3186512e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(profile={'max_input_tokens': 16385, 'max_output_tokens': 4096, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': False, 'structured_output': False, 'image_url_inputs': False, 'pdf_inputs': False, 'pdf_tool_message': False, 'image_tool_message': False, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x72b4988b9cd0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x72b49842af00>, root_client=<openai.OpenAI object at 0x72b498426d50>, root_async_client=<openai.AsyncOpenAI object at 0x72b4988b71a0>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_openai  import ChatOpenAI\n",
    "\n",
    "llm_model = \"gpt-3.5-turbo\"\n",
    "chat = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3402f3ff",
   "metadata": {},
   "source": [
    "## Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f748f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text that is delimited by triple backticks into a style that is {style}.\n",
    "text: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "473bbbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['style', 'text'] input_types={} partial_variables={} template='Translate the text that is delimited by triple backticks into a style that is {style}.\\ntext: ```{text}```\\n'\n",
      "['style', 'text']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "\n",
    "print(prompt_template.messages[0].prompt)\n",
    "print(prompt_template.messages[0].prompt.input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9bdb8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n",
      "content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone.\\ntext: ```Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!```\\n\" additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "customer_style = \"\"\"American English in a calm and respectful tone\"\"\"\n",
    "customer_email = \"\"\"Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\"\"\"\n",
    "\n",
    "customer_messages = prompt_template.format_messages(style=customer_style, text=customer_email)\n",
    "\n",
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))\n",
    "print(customer_messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df82adb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am really frustrated that my blender lid flew off and splattered my kitchen walls with smoothie! And to make matters worse, the warranty doesn't cover the cost of cleaning up my kitchen. I could really use your help right now, friend.\n"
     ]
    }
   ],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat.invoke(customer_messages)\n",
    "\n",
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72787b76",
   "metadata": {},
   "source": [
    "## Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea13e07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
